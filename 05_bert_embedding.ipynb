{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary\n",
    "\n",
    "- bert input embedding:一种查表操作（lookup table）\n",
    "    - 查表\n",
    "        - token embedding:30522*768\n",
    "        - segment embedding:0/1 * 8 =768\n",
    "        - position embedding:512*768\n",
    "    - 后处理\n",
    "        - layer norm\n",
    "        - dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = 'this is a test sentence'\n",
    "input = tokenizer(test_sent, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input['input_ids']\n",
    "token_type_ids = input['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [-0.6485,  0.6739, -0.0932,  ...,  0.4475,  0.6696,  0.1820],\n",
       "         [-0.6270, -0.0633, -0.3143,  ...,  0.3427,  0.4636,  0.4594],\n",
       "         ...,\n",
       "         [ 0.6010, -0.6970, -0.2001,  ...,  0.2960,  0.2060, -1.7181],\n",
       "         [ 0.8323,  0.2878,  0.0021,  ...,  0.2628, -1.1310, -1.2708],\n",
       "         [-0.1481, -0.2948, -0.1690,  ..., -0.5009,  0.2544, -0.0700]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(input_ids, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ids = torch.arange(input_ids.shape[1])\n",
    "print(input_ids.shape)\n",
    "pos_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. token embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3630e-02, -2.6490e-02, -2.3503e-02,  ...,  8.6805e-03,\n",
       "           7.1340e-03,  1.5147e-02],\n",
       "         [-5.7095e-02,  1.5283e-02, -4.6868e-03,  ..., -3.2484e-03,\n",
       "           9.7317e-05,  9.4175e-03],\n",
       "         [-3.6044e-02, -2.4606e-02, -2.5735e-02,  ...,  3.3691e-03,\n",
       "          -1.8300e-03,  2.6855e-02],\n",
       "         ...,\n",
       "         [ 2.3670e-02, -6.1351e-02, -2.9575e-02,  ..., -1.0239e-02,\n",
       "          -7.2316e-03, -1.1745e-01],\n",
       "         [ 3.2079e-02,  6.3135e-03, -6.4352e-03,  ..., -1.1689e-03,\n",
       "          -1.0810e-01, -8.9524e-02],\n",
       "         [-1.4521e-02, -9.9615e-03,  6.0263e-03,  ..., -2.5035e-02,\n",
       "           4.6379e-03, -1.5378e-03]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding = model.embeddings.word_embeddings(input_ids)\n",
    "token_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. segment embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         ...,\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "         [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_embedding = model.embeddings.token_type_embeddings(token_type_ids)\n",
    "segment_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,\n",
       "          6.8312e-04,  1.5441e-02],\n",
       "        [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,\n",
       "          2.9753e-02, -5.3247e-03],\n",
       "        [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,\n",
       "          1.8741e-02, -7.3140e-03],\n",
       "        ...,\n",
       "        [-5.6087e-03, -1.0445e-02, -7.2288e-03,  ...,  2.0837e-02,\n",
       "          3.5402e-03,  4.7708e-03],\n",
       "        [-3.0871e-03, -1.8956e-02, -1.8930e-02,  ...,  7.4045e-03,\n",
       "          2.0183e-02,  3.4077e-03],\n",
       "        [ 6.4257e-03, -1.7664e-02, -2.2067e-02,  ...,  6.7531e-04,\n",
       "          1.1108e-02,  3.7521e-03]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embedding = model.embeddings.position_embeddings(pos_ids)\n",
    "position_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. input embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0316, -0.0411, -0.0564,  ...,  0.0021,  0.0044,  0.0219],\n",
       "         [-0.0489,  0.0285, -0.0204,  ...,  0.0190,  0.0265, -0.0045],\n",
       "         [-0.0469, -0.0156, -0.0336,  ...,  0.0117,  0.0135,  0.0109],\n",
       "         ...,\n",
       "         [ 0.0185, -0.0608, -0.0331,  ...,  0.0040, -0.0071, -0.1213],\n",
       "         [ 0.0294, -0.0017, -0.0217,  ..., -0.0004, -0.0913, -0.0948],\n",
       "         [-0.0077, -0.0166, -0.0123,  ..., -0.0310,  0.0124, -0.0064]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding = token_embedding + segment_embedding + position_embedding\n",
    "input_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [-0.6485,  0.6739, -0.0932,  ...,  0.4475,  0.6696,  0.1820],\n",
       "         [-0.6270, -0.0633, -0.3143,  ...,  0.3427,  0.4636,  0.4594],\n",
       "         ...,\n",
       "         [ 0.6010, -0.6970, -0.2001,  ...,  0.2960,  0.2060, -1.7181],\n",
       "         [ 0.8323,  0.2878,  0.0021,  ...,  0.2628, -1.1310, -1.2708],\n",
       "         [-0.1481, -0.2948, -0.1690,  ..., -0.5009,  0.2544, -0.0700]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = model.embeddings.LayerNorm(input_embedding)\n",
    "embedding = model.embeddings.dropout(embedding)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
