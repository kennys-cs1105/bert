{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"After stealing money from the bank vault, the bank robber was seen\" \\\n",
    "\"fishing on the Mississippi river bank.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2044, 11065,  2769,  2013,  1996,  2924, 11632,  1010,  1996,\n",
       "          2924, 27307,  2001,  2464,  7529,  2075,  2006,  1996,  5900,  2314,\n",
       "          2924,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_input = tokenizer(text, return_tensors='pt')\n",
    "token_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2044, 11065,  2769,  2013,  1996,  2924, 11632,  1010,  1996,\n",
       "           2924, 27307,  2001,  2464,  7529,  2075,  2006,  1996,  5900,  2314,\n",
       "           2924,  1012,   102]]),\n",
       " torch.Size([1, 23]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_input['input_ids'], token_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. model forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**token_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4753, -0.1761, -0.5085,  ..., -0.1615,  0.2146,  0.4629],\n",
       "         [-0.1863, -0.2398, -0.3129,  ..., -0.4734,  0.3565, -0.0989],\n",
       "         [-0.2837, -0.4107,  0.1239,  ..., -0.4277, -0.2827, -0.2913],\n",
       "         ...,\n",
       "         [ 0.4568, -0.2481, -0.0512,  ..., -0.5370, -0.4463,  0.3166],\n",
       "         [ 0.4360, -0.0936, -0.2603,  ...,  0.0103, -0.5848, -0.2151],\n",
       "         [-0.0156, -0.1622, -0.6312,  ...,  0.3231,  0.0220, -0.2061]]]), pooler_output=tensor([[-4.1921e-01, -2.1681e-01, -4.3243e-01,  1.0251e-01,  2.4461e-01,\n",
       "         -4.7945e-02,  2.7057e-01,  2.4123e-01, -3.1746e-02, -9.9959e-01,\n",
       "         -1.2217e-01,  4.5575e-01,  9.7423e-01, -1.9121e-01,  7.2764e-01,\n",
       "         -2.0316e-01,  1.1413e-01, -2.0924e-01,  3.9048e-02,  6.4868e-01,\n",
       "          4.0017e-01,  9.9856e-01,  3.3952e-01,  1.1784e-01,  1.3931e-01,\n",
       "          6.4271e-01, -3.9276e-01,  7.9743e-01,  8.8027e-01,  7.0781e-01,\n",
       "         -1.4160e-01,  1.9248e-02, -9.8340e-01, -3.3368e-02, -4.2779e-01,\n",
       "         -9.6833e-01,  1.4192e-01, -5.4183e-01,  2.5948e-01,  8.1293e-02,\n",
       "         -6.6085e-01,  1.8670e-01,  9.9945e-01, -6.6039e-01,  2.5604e-01,\n",
       "         -1.7391e-01, -9.9878e-01,  1.3117e-01, -7.2896e-01,  2.5849e-01,\n",
       "          2.6783e-01,  5.6524e-01,  2.5692e-03,  2.1209e-01,  3.2570e-01,\n",
       "         -9.1817e-02, -2.5027e-01, -1.9631e-02, -6.6154e-02, -4.1220e-01,\n",
       "         -5.3175e-01,  6.3834e-02, -2.4332e-01, -7.1006e-01,  3.4074e-01,\n",
       "         -2.8956e-01,  4.7980e-03, -6.8843e-02,  1.5191e-01, -1.0789e-01,\n",
       "          4.8510e-01,  1.3973e-01,  5.1443e-02, -6.4711e-01, -1.9504e-01,\n",
       "          2.0726e-01, -5.4556e-01,  9.9999e-01,  3.4462e-01, -9.5008e-01,\n",
       "          3.4101e-01, -6.2544e-02,  4.2498e-01,  6.9434e-01, -5.1273e-01,\n",
       "         -9.9994e-01,  2.1358e-01, -2.1203e-01, -9.8008e-01,  5.4929e-02,\n",
       "          4.0677e-01, -1.2661e-01,  3.4921e-01,  4.5750e-01, -5.9330e-02,\n",
       "         -3.5297e-01, -2.5286e-01, -4.5867e-01, -8.9140e-04,  1.6735e-01,\n",
       "         -1.5135e-01, -1.7188e-01,  3.1608e-03, -1.6061e-01,  9.3941e-02,\n",
       "         -2.8395e-01,  1.0983e-01,  6.7018e-02, -4.9462e-01,  3.8599e-01,\n",
       "          4.1656e-01, -1.0418e-01,  2.1284e-01, -8.9333e-01,  4.4881e-01,\n",
       "         -3.1389e-01, -9.8222e-01, -4.6424e-01, -9.8391e-01,  5.5821e-01,\n",
       "         -9.7962e-02, -2.0494e-01,  8.5274e-01,  1.1920e-02,  2.2237e-01,\n",
       "          2.0031e-01, -4.4629e-01, -1.0000e+00,  2.4759e-01,  1.7943e-01,\n",
       "          1.1022e-01, -1.0340e-01, -9.5252e-01, -9.3656e-01,  1.9254e-01,\n",
       "          8.2189e-01,  1.5748e-01,  9.9813e-01, -2.4142e-01,  9.1908e-01,\n",
       "          1.9223e-01, -1.5646e-01,  1.0327e-01, -3.7015e-01,  1.5521e-01,\n",
       "         -5.2501e-01,  2.3232e-02,  2.4482e-01,  2.2474e-01,  4.8368e-02,\n",
       "         -4.0327e-01, -1.9471e-01,  1.7089e-01, -7.0179e-01, -1.8021e-01,\n",
       "          8.6878e-01, -2.7779e-01, -1.2114e-01,  5.0109e-01, -1.2199e-01,\n",
       "         -1.0741e-02,  5.6545e-01,  1.7321e-02,  1.8098e-01,  2.2785e-01,\n",
       "          3.0433e-01, -6.1000e-01,  1.7120e-01, -6.6673e-01,  1.2081e-01,\n",
       "          1.6239e-01, -1.9085e-01, -2.6572e-01, -9.7901e-01, -1.1444e-01,\n",
       "          3.0336e-01,  9.6469e-01,  4.7335e-01,  1.7875e-01,  1.9506e-01,\n",
       "         -1.5522e-01,  3.5825e-02, -9.4041e-01,  9.7428e-01,  1.2487e-02,\n",
       "          2.3308e-01, -6.7259e-01,  4.5146e-01, -6.6216e-01, -5.7035e-01,\n",
       "          5.3692e-01, -1.9924e-01, -5.6611e-01,  6.2960e-02, -1.9461e-01,\n",
       "         -7.2336e-02, -5.1842e-01,  4.0925e-01, -2.1407e-01, -2.4838e-01,\n",
       "          7.9561e-02,  8.6885e-01,  4.7269e-01,  1.7778e-01, -2.1454e-01,\n",
       "          1.7631e-01, -6.6661e-01, -1.4492e-01, -9.2524e-02,  5.4057e-02,\n",
       "         -5.3790e-02,  9.7831e-01, -4.1089e-01,  7.1882e-02, -7.2195e-01,\n",
       "         -9.7522e-01, -2.1598e-01, -6.5548e-01,  5.8463e-02, -3.2898e-01,\n",
       "          2.4417e-01, -4.5985e-01, -5.3362e-01, -5.4557e-02,  1.1705e-01,\n",
       "         -6.1461e-01,  2.4114e-01, -4.5594e-01,  2.4697e-01, -2.3954e-01,\n",
       "          7.7422e-01,  5.0581e-01, -4.5740e-01, -4.2138e-01,  9.0681e-01,\n",
       "         -4.3486e-01, -6.2318e-01, -1.9170e-01, -7.6576e-02,  5.6083e-01,\n",
       "         -5.4750e-01,  9.3824e-01,  3.6438e-01,  1.1910e-01, -8.8515e-01,\n",
       "         -4.3964e-01, -2.3554e-01,  3.0184e-01,  4.3973e-02, -7.2930e-01,\n",
       "          1.4979e-01,  3.8789e-01,  1.8987e-01,  8.4360e-01, -3.0035e-01,\n",
       "          4.6094e-01, -8.2400e-01, -9.1264e-01, -9.7276e-01,  3.1116e-01,\n",
       "         -9.7974e-01,  5.8277e-01,  1.0668e-01,  1.7616e-01, -2.7477e-01,\n",
       "         -2.4594e-01, -9.3277e-01,  4.4875e-02,  6.3788e-03,  6.8497e-01,\n",
       "         -4.1288e-01, -3.6172e-01, -3.3488e-01, -8.8175e-01, -1.3773e-01,\n",
       "          3.7713e-02,  4.7831e-01,  3.3519e-02, -8.3988e-01,  2.6492e-01,\n",
       "          4.0536e-01,  2.8871e-01, -6.1425e-01,  8.7137e-01,  9.9993e-01,\n",
       "          9.6360e-01,  7.3771e-01,  2.2645e-01, -9.9430e-01, -8.5884e-01,\n",
       "          9.9976e-01, -8.5796e-01, -9.9996e-01, -8.0217e-01, -4.1969e-01,\n",
       "          8.9130e-02, -1.0000e+00, -3.9590e-02,  9.4738e-02, -8.6008e-01,\n",
       "         -3.9108e-03,  9.5457e-01,  4.3025e-01, -1.0000e+00,  8.0091e-01,\n",
       "          7.5149e-01, -5.0582e-01,  5.3428e-01, -1.2132e-01,  9.5313e-01,\n",
       "          2.3947e-01,  4.6965e-01, -1.9772e-01,  4.1721e-01, -5.6307e-01,\n",
       "         -4.8518e-01, -1.1831e-01, -4.6018e-01,  9.6969e-01, -6.0713e-02,\n",
       "         -1.5838e-01, -7.7780e-01,  3.5433e-01,  2.9561e-02, -4.2962e-01,\n",
       "         -8.8907e-01, -1.4838e-01,  3.0887e-01,  3.8343e-01,  5.3194e-02,\n",
       "          1.4504e-01, -3.7472e-01,  4.4200e-02, -3.2190e-01, -4.9186e-01,\n",
       "          5.5774e-01, -7.3963e-01, -8.3491e-02,  5.5280e-01, -1.0715e-01,\n",
       "          3.1294e-01, -9.3977e-01,  9.0452e-01, -3.0502e-01,  2.7289e-01,\n",
       "          1.0000e+00,  8.0162e-01, -4.5152e-01,  2.2432e-01,  7.4312e-02,\n",
       "          3.4197e-01,  9.9997e-01,  9.0971e-02, -9.6628e-01, -5.0858e-01,\n",
       "          2.6323e-01, -3.5238e-01, -3.1433e-01,  9.9416e-01, -1.0065e-01,\n",
       "         -1.8320e-01,  1.8193e-03,  9.7728e-01, -9.8147e-01,  9.3531e-01,\n",
       "         -5.5527e-01, -9.3179e-01,  9.3484e-01,  8.6018e-01, -1.7948e-01,\n",
       "         -5.0454e-01,  3.1494e-02,  4.5697e-01,  6.3205e-02, -4.8677e-01,\n",
       "          3.7060e-01,  2.2557e-01,  6.7174e-02,  6.4210e-01,  3.5366e-01,\n",
       "         -4.4122e-01,  1.5728e-01, -2.5803e-01,  1.2001e-01,  7.3698e-01,\n",
       "          2.4996e-01, -3.3129e-02, -3.5554e-02, -1.9032e-01, -7.3030e-01,\n",
       "         -9.0415e-01,  1.8675e-01,  9.9999e-01, -4.1317e-02,  6.1922e-01,\n",
       "          2.1772e-01,  4.5093e-02, -2.3853e-01,  3.1787e-01,  1.8592e-01,\n",
       "         -2.5705e-01, -3.7707e-01,  5.2427e-01, -4.7360e-01, -9.9219e-01,\n",
       "         -6.6024e-02, -4.7820e-02,  1.5200e-01,  9.9056e-01,  5.1628e-01,\n",
       "          7.3836e-02,  2.4313e-01,  8.5676e-01, -1.3866e-01, -2.0718e-01,\n",
       "         -4.8019e-02,  9.4186e-01, -1.7398e-01,  4.0054e-01,  7.1560e-02,\n",
       "         -2.8597e-02,  1.1761e-02, -4.0650e-01, -1.9679e-01, -8.5871e-01,\n",
       "          3.6811e-01, -9.4383e-01,  8.6341e-01,  7.4932e-01,  3.1318e-01,\n",
       "          5.3607e-02,  3.4237e-01,  9.9999e-01, -9.7173e-01, -1.0027e-03,\n",
       "          8.4899e-01, -3.2086e-01, -9.9466e-01, -1.9138e-01, -2.4623e-01,\n",
       "          5.3244e-03,  9.8936e-02,  4.2973e-02, -9.8787e-03, -9.4551e-01,\n",
       "         -1.7013e-01,  6.0112e-01, -1.8917e-01, -9.7794e-01,  2.1756e-01,\n",
       "          1.4662e-01,  2.4976e-01, -8.8126e-01, -1.4127e-01, -3.7431e-01,\n",
       "          5.0513e-02,  5.7569e-02, -8.8512e-01,  4.8445e-01, -2.5409e-01,\n",
       "          2.7754e-01, -8.1499e-02,  4.5749e-01,  2.2397e-02,  9.5402e-01,\n",
       "         -7.4385e-01, -2.2617e-01, -6.6833e-02, -6.6075e-01,  2.7465e-01,\n",
       "         -1.6375e-01, -4.3467e-01, -1.7128e-01,  9.9999e-01, -3.1718e-01,\n",
       "          2.6378e-01,  1.8639e-01, -9.4631e-02, -1.2233e-01,  1.2617e-01,\n",
       "          5.4251e-01,  9.3109e-02,  4.1349e-01, -2.7170e-01,  8.2054e-01,\n",
       "         -1.6635e-01,  2.3423e-01,  5.8002e-01, -3.4507e-01,  5.7474e-01,\n",
       "          6.1032e-01,  1.1800e-01,  1.3716e-01,  3.6585e-03,  6.6390e-01,\n",
       "          2.5836e-02, -2.1348e-01, -2.2913e-01,  1.0612e-02, -2.0986e-01,\n",
       "          7.9791e-01,  9.9999e-01,  1.2354e-01,  4.2631e-01, -9.8971e-01,\n",
       "         -5.7803e-01, -6.7177e-01,  9.9992e-01,  8.2067e-01, -6.6839e-01,\n",
       "          4.0016e-01,  3.5334e-01, -2.0737e-01, -2.5677e-01, -1.1524e-01,\n",
       "         -2.1754e-01,  1.6525e-01, -9.1950e-02,  9.3976e-01, -4.7215e-01,\n",
       "         -9.7364e-01, -3.8471e-01,  2.3804e-01, -8.9762e-01,  9.9678e-01,\n",
       "         -3.9354e-01, -1.5624e-01, -1.9972e-01, -2.2845e-01, -9.5411e-01,\n",
       "         -1.2623e-01, -9.6940e-01, -1.0279e-01, -3.6524e-02,  9.4483e-01,\n",
       "          2.4517e-01, -4.4034e-01, -7.4091e-01,  6.4771e-01,  1.7068e-01,\n",
       "         -5.1533e-01, -9.1192e-01,  9.5610e-01, -8.0752e-01,  2.1430e-01,\n",
       "          9.9971e-01,  4.2745e-01, -1.7502e-01,  5.6444e-02, -8.9064e-02,\n",
       "          2.2603e-01, -2.1872e-01,  4.4126e-01, -8.5847e-01,  8.6862e-03,\n",
       "         -8.3369e-03,  3.0912e-01,  1.5890e-02, -8.5786e-01,  5.2334e-01,\n",
       "         -4.6785e-02, -4.0439e-01, -4.0368e-01,  1.1318e-02,  2.4453e-01,\n",
       "          4.7986e-01, -1.1947e-01,  4.7383e-02,  1.2969e-01,  1.4306e-01,\n",
       "         -6.6597e-01, -1.9745e-01, -2.2171e-01, -9.9926e-01,  3.8151e-01,\n",
       "         -1.0000e+00,  5.0491e-01, -5.1948e-01, -1.3133e-01,  6.4332e-01,\n",
       "          7.0082e-01,  5.7988e-01, -2.9246e-01, -9.0895e-02,  8.0877e-01,\n",
       "          5.0526e-01, -2.7468e-02, -3.4303e-02, -3.6593e-01,  1.0633e-01,\n",
       "          1.0058e-01,  2.4598e-02, -5.7708e-02,  4.8723e-01, -1.9590e-01,\n",
       "          1.0000e+00, -2.1568e-02, -1.1851e-01, -3.2964e-01,  1.1058e-01,\n",
       "         -1.8754e-01,  9.9995e-01,  4.1911e-02, -9.4270e-01,  9.0986e-02,\n",
       "         -3.2089e-01, -4.1023e-01,  3.7063e-01, -9.5338e-02, -6.6137e-01,\n",
       "         -5.8750e-01,  6.3078e-01,  9.4779e-02, -5.7927e-01,  3.4786e-01,\n",
       "         -1.3856e-01, -1.3040e-01, -1.2124e-01,  6.0436e-01,  9.7719e-01,\n",
       "          7.1808e-01,  2.0599e-01, -9.2430e-01, -1.7590e-01,  8.9975e-01,\n",
       "         -2.8827e-02, -2.7512e-01, -4.3274e-02,  9.9996e-01,  2.9756e-01,\n",
       "         -6.3847e-01,  2.1797e-01, -7.7585e-01, -2.1480e-01, -5.7244e-01,\n",
       "          1.9102e-01,  2.0073e-03,  8.4515e-01, -1.6129e-01,  8.5688e-01,\n",
       "         -5.6484e-01, -1.5385e-01, -2.4861e-01,  4.4723e-01,  2.2790e-01,\n",
       "         -8.1711e-01, -9.7535e-01, -9.8264e-01,  3.8708e-01, -2.7378e-01,\n",
       "         -5.5562e-02,  3.3831e-01,  4.2662e-02,  1.3829e-01,  3.5597e-01,\n",
       "         -9.9998e-01,  8.9029e-01,  2.3075e-01,  4.1059e-01,  9.5632e-01,\n",
       "          3.1036e-01,  4.9800e-01,  2.8411e-01, -9.7469e-01, -2.3548e-01,\n",
       "         -1.8382e-01, -7.6361e-02,  2.9412e-01,  1.8579e-01,  5.0468e-01,\n",
       "          1.6715e-01, -3.1117e-01, -5.1303e-01,  1.0623e-02, -9.4832e-01,\n",
       "         -9.7862e-01,  3.3671e-01,  3.2240e-01, -6.6424e-02,  9.0142e-01,\n",
       "         -1.8250e-01,  1.3075e-01,  5.6653e-01, -2.6130e-01, -4.5525e-02,\n",
       "          5.0450e-01,  7.8718e-02, -7.8656e-02,  5.0250e-01,  7.5024e-01,\n",
       "          7.1485e-01,  9.6995e-01, -4.5875e-01,  1.4348e-01, -2.6795e-01,\n",
       "          2.1039e-01,  8.6128e-01, -8.8843e-01,  4.5255e-02,  1.2729e-01,\n",
       "         -4.7677e-02,  7.9942e-02, -1.6171e-01, -8.1878e-02,  9.2646e-01,\n",
       "         -8.0219e-02,  1.5621e-01, -1.2880e-01,  2.8731e-01, -3.5011e-01,\n",
       "         -9.8257e-02, -6.7264e-01, -3.2614e-01,  4.8660e-01, -3.1731e-01,\n",
       "          8.1596e-01,  4.8002e-01,  3.2618e-02, -3.4849e-01, -9.6905e-02,\n",
       "          4.0703e-01, -8.7948e-01, -2.5451e-02,  1.8086e-02,  7.0594e-01,\n",
       "          1.5255e-01, -4.9969e-01,  9.7431e-01, -3.4130e-01, -2.8486e-01,\n",
       "         -1.9538e-01, -4.4697e-01,  3.1001e-01, -5.8966e-01, -2.7693e-01,\n",
       "         -2.8049e-01,  6.7239e-01,  2.7693e-01,  9.9931e-01, -2.7018e-01,\n",
       "         -6.5525e-02, -2.2824e-01, -2.3836e-01,  2.8443e-02, -2.2626e-01,\n",
       "         -9.9998e-01,  1.8266e-01, -9.3675e-02,  2.1314e-01, -3.8212e-01,\n",
       "          6.8530e-01, -3.0645e-01, -4.9699e-01, -5.0914e-02,  3.7011e-01,\n",
       "          2.2563e-01, -4.2260e-01, -1.4010e-01,  4.8511e-01, -1.2328e-01,\n",
       "          6.9204e-01,  4.6747e-01,  1.2901e-01,  7.4951e-01,  5.4294e-01,\n",
       "          7.8762e-02, -4.5109e-01,  5.2823e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)\n",
    "# type(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Tensor)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[1]), type(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1][-1] == outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs[1])):\n",
    "    print(i, outputs[1][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
